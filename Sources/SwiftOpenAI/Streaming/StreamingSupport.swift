import Foundation

/// ÂèëÈÄÅÊ∂àÊÅØÁöÑ‰∏ªÂáΩÊï∞ÔºåÊèê‰æõ‰∏éMacPaw OpenAIÁõ∏‰ººÁöÑ‰ΩøÁî®ÊñπÂºèÔºàÊîØÊåÅÁõ¥Êé•‰º†ÂÖ•Â∑•ÂÖ∑ÂØπË±°Ôºâ
public func sendMessage(
    modelInfo: AIModelInfoValue,
    messages: [ChatQuery.ChatCompletionMessageParam],
    frequencyPenalty: Double? = nil,
    maxCompletionTokens: Int? = nil,
    n: Int? = nil,
    parallelToolCalls: Bool? = nil,
    prediction: ChatQuery.PredictedOutputConfig? = nil,
    presencePenalty: Double? = nil,
    responseFormat: ChatQuery.ResponseFormat? = nil,
    stop: ChatQuery.Stop? = nil,
    temperature: Double? = 0.6,
    toolChoice: ChatQuery.ChatCompletionFunctionCallOptionParam? = nil,
    tools: [any OpenAIToolConvertible]? = nil,  // üÜï Áõ¥Êé•ÊîØÊåÅÂ∑•ÂÖ∑ÂØπË±°
    topP: Double? = nil,
    user: String? = nil,
    stream: Bool = true,
    action: (OpenAIChatStreamResult) async throws -> Void
) async throws -> OpenAIChatResult {
    // Ëá™Âä®ËΩ¨Êç¢Â∑•ÂÖ∑ÂØπË±°‰∏∫ChatCompletionToolParam
    let convertedTools = tools?.map { $0.asChatCompletionTool }
    
    return try await sendMessage(
        modelInfo: modelInfo,
        messages: messages,
        frequencyPenalty: frequencyPenalty,
        maxCompletionTokens: maxCompletionTokens,
        n: n,
        parallelToolCalls: parallelToolCalls,
        prediction: prediction,
        presencePenalty: presencePenalty,
        responseFormat: responseFormat,
        stop: stop,
        temperature: temperature,
        toolChoice: toolChoice,
        tools: convertedTools,  // ‰ΩøÁî®ËΩ¨Êç¢ÂêéÁöÑÂ∑•ÂÖ∑ÂèÇÊï∞
        topP: topP,
        user: user,
        stream: stream,
        action: action
    )
}

/// ÂèëÈÄÅÊ∂àÊÅØÁöÑ‰∏ªÂáΩÊï∞ÔºåÊèê‰æõ‰∏éMacPaw OpenAIÁõ∏‰ººÁöÑ‰ΩøÁî®ÊñπÂºèÔºàÂéüÂßãAPIÔºâ
public func sendMessage(
    modelInfo: AIModelInfoValue,
    messages: [ChatQuery.ChatCompletionMessageParam],
    frequencyPenalty: Double? = nil,
    maxCompletionTokens: Int? = nil,
    n: Int? = nil,
    parallelToolCalls: Bool? = nil,
    prediction: ChatQuery.PredictedOutputConfig? = nil,
    presencePenalty: Double? = nil,
    responseFormat: ChatQuery.ResponseFormat? = nil,
    stop: ChatQuery.Stop? = nil,
    temperature: Double? = 0.6,
    toolChoice: ChatQuery.ChatCompletionFunctionCallOptionParam? = nil,
    tools: [ChatQuery.ChatCompletionToolParam]? = nil,
    topP: Double? = nil,
    user: String? = nil,
    stream: Bool = true,
    action: (OpenAIChatStreamResult) async throws -> Void
) async throws -> OpenAIChatResult {
    let actorHelper = await OpenAISendMessageValueHelper()
    let resolvedModelInfo = modelInfo
    
    // ÂàõÂª∫OpenAIÈÖçÁΩÆ
    let configuration = OpenAIConfiguration(
        token: resolvedModelInfo.token,
        host: resolvedModelInfo.host,
        port: resolvedModelInfo.port,
        scheme: resolvedModelInfo.scheme,
        basePath: resolvedModelInfo.basePath
    )
    
    let openAI = OpenAI(configuration: configuration)
    
    // ÂàõÂª∫Êü•ËØ¢
    let query = ChatQuery(
        messages: messages,
        model: resolvedModelInfo.modelID,
        frequencyPenalty: frequencyPenalty,
        maxCompletionTokens: maxCompletionTokens,
        n: n,
        parallelToolCalls: parallelToolCalls,
        prediction: prediction,
        presencePenalty: presencePenalty,
        responseFormat: responseFormat,
        stop: stop,
        temperature: temperature,
        toolChoice: toolChoice,
        tools: tools,
        topP: topP,
        user: user,
        stream: stream
    )
    
    // Â§ÑÁêÜÊµÅÂºèÂìçÂ∫î
    for try await result in openAI.chatsStream(query: query) {
        try Task.checkCancellation()
        
        if let choice = result.choices.first {
            await actorHelper.setText(
                thinkingText: choice.delta.reasoning ?? "",
                text: choice.delta.content ?? ""
            )
            
            if let toolCalls = choice.delta.toolCalls {
                for call in toolCalls {
                    if let index = await actorHelper.allToolCalls.firstIndex(where: { $0.index == call.index }) {
                        // Êõ¥Êñ∞Â∑≤Â≠òÂú®ÁöÑtool call
                        let existingCall = await actorHelper.allToolCalls[index]
                        let updatedCall = ChatStreamResult.Choice.ChoiceDelta.ChoiceDeltaToolCall(
                            index: existingCall.index,
                            id: existingCall.id ?? call.id,
                            type: existingCall.type ?? call.type,
                            function: ChatStreamResult.Choice.ChoiceDelta.ChoiceDeltaToolCall.ChoiceDeltaToolCallFunction(
                                name: (existingCall.function?.name ?? "") + (call.function?.name ?? ""),
                                arguments: (existingCall.function?.arguments ?? "") + (call.function?.arguments ?? "")
                            )
                        )
                        await actorHelper.setAllToolCalls(index: index, call: updatedCall)
                    } else {
                        // Ê∑ªÂä†Êñ∞ÁöÑtool call
                        await actorHelper.appendAllToolCalls(call)
                    }
                }
            }
            
            // Ë∞ÉÁî®Áî®Êà∑Êèê‰æõÁöÑactionÂõûË∞É
            try await action(OpenAIChatStreamResult(
                subThinkingText: choice.delta.reasoning ?? "",
                subText: choice.delta.content ?? "",
                fullThinkingText: await actorHelper.fullThinkingText,
                fullText: await actorHelper.fullText,
                state: await actorHelper.state,
                allToolCalls: await actorHelper.allToolCalls
            ))
        }
    }
    
    // ËÆæÁΩÆÂÆåÊàêÁä∂ÊÄÅ
    await actorHelper.setState(.text)
    
    // ËøîÂõûÊúÄÁªàÁªìÊûú
    return await OpenAIChatResult(
        fullThinkingText: actorHelper.fullThinkingText,
        fullText: actorHelper.fullText,
        state: actorHelper.state,
        allToolCalls: actorHelper.allToolCalls
    )
}
